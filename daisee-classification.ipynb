{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7db3e96",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-15T19:37:32.177154Z",
     "iopub.status.busy": "2023-05-15T19:37:32.176743Z",
     "iopub.status.idle": "2023-05-15T19:37:38.551034Z",
     "shell.execute_reply": "2023-05-15T19:37:38.549995Z"
    },
    "papermill": {
     "duration": 6.384097,
     "end_time": "2023-05-15T19:37:38.553912",
     "exception": false,
     "start_time": "2023-05-15T19:37:32.169815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm, metrics, preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7655f3f2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-05-15T19:37:38.566431Z",
     "iopub.status.busy": "2023-05-15T19:37:38.565565Z",
     "iopub.status.idle": "2023-05-15T19:37:53.808251Z",
     "shell.execute_reply": "2023-05-15T19:37:53.806861Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 15.252046,
     "end_time": "2023-05-15T19:37:53.811222",
     "exception": false,
     "start_time": "2023-05-15T19:37:38.559176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet-pytorch\r\n",
      "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (2.28.2)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (9.5.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (0.15.1+cpu)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (2022.12.7)\r\n",
      "Requirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.0.0+cpu)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (3.11.0)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (3.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (1.11.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->torchvision->facenet-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchvision->facenet-pytorch) (2.1.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchvision->facenet-pytorch) (1.3.0)\r\n",
      "Installing collected packages: facenet-pytorch\r\n",
      "Successfully installed facenet-pytorch-2.5.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch\n",
    "from facenet_pytorch import MTCNN # pretrained model for image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd8459d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T19:37:53.824957Z",
     "iopub.status.busy": "2023-05-15T19:37:53.824553Z",
     "iopub.status.idle": "2023-05-15T19:37:53.887514Z",
     "shell.execute_reply": "2023-05-15T19:37:53.886349Z"
    },
    "papermill": {
     "duration": 0.073367,
     "end_time": "2023-05-15T19:37:53.890293",
     "exception": false,
     "start_time": "2023-05-15T19:37:53.816926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../working/mtcnn.pb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "copyfile(src = \"../input/mtcnn-model/facial_analysis_kaggle.py\", dst = \"../working/facial_analysis_kaggle.py\")\n",
    "copyfile(src = \"../input/mtcnn-model/mtcnn.pb\", dst = \"../working/mtcnn.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7577cec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T19:37:53.904249Z",
     "iopub.status.busy": "2023-05-15T19:37:53.903541Z",
     "iopub.status.idle": "2023-05-15T19:38:02.737894Z",
     "shell.execute_reply": "2023-05-15T19:38:02.737077Z"
    },
    "papermill": {
     "duration": 8.84391,
     "end_time": "2023-05-15T19:38:02.740268",
     "exception": false,
     "start_time": "2023-05-15T19:37:53.896358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mtcnn.pb\n"
     ]
    }
   ],
   "source": [
    "from facial_analysis_kaggle import FacialImageProcessing\n",
    "\n",
    "imgProcessing = FacialImageProcessing(False)\n",
    "mtcnn = MTCNN(keep_all=True, min_face_size=40, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2fd42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T19:38:02.755068Z",
     "iopub.status.busy": "2023-05-15T19:38:02.754019Z",
     "iopub.status.idle": "2023-05-15T19:38:02.768986Z",
     "shell.execute_reply": "2023-05-15T19:38:02.768129Z"
    },
    "papermill": {
     "duration": 0.024745,
     "end_time": "2023-05-15T19:38:02.771425",
     "exception": false,
     "start_time": "2023-05-15T19:38:02.746680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_and_save_faces(data_path, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for person in tqdm(os.listdir(data_path)):\n",
    "        person_path = data_path + '/' + person\n",
    "        # print(person_path)\n",
    "        if not os.path.exists(save_dir + '/' + person):\n",
    "            os.makedirs(save_dir + '/' + person)\n",
    "        for video_name in os.listdir(person_path):\n",
    "            video_format = list(os.listdir(person_path + '/' + video_name))[0].split('.')[-1]\n",
    "            video_path = person_path + '/' + video_name + '/' + video_name + '.' + video_format\n",
    "            video = cv2.VideoCapture(video_path)\n",
    "            fps = video.get(cv2.CAP_PROP_FPS)\n",
    "            images = []\n",
    "            filenames = []\n",
    "            i = 0.\n",
    "            stride = 1.0\n",
    "            \n",
    "            frame_times = []\n",
    "\n",
    "            while video.isOpened():\n",
    "                ret, frame = video.read()\n",
    "                if ret:\n",
    "                    images.append(frame)\n",
    "                    frame_times.append(i)\n",
    "                    i += stride\n",
    "                    video.set(1, round(i * fps))\n",
    "                else:\n",
    "                    video.release()\n",
    "                    break\n",
    "                    \n",
    "            for i, image in enumerate(images):\n",
    "                bounding_boxes, _ = imgProcessing.detect_faces(image)\n",
    "                # bounding_boxes, _, _ = mtcnn.detect(image, landmarks=True)\n",
    "                \n",
    "                if bounding_boxes is None or len(bounding_boxes)==0:\n",
    "                    # print('No faces found for ',video_path + '_' + str(i+1))\n",
    "                    face_img = image\n",
    "                    faceFound='noface'\n",
    "                else:\n",
    "                    if len(bounding_boxes)>1:\n",
    "                        # print('Too many faces (',len(bounding_boxes),') found for ',filename)\n",
    "                        bounding_boxes=bounding_boxes[:1]\n",
    "                    \n",
    "                    b=[int(bi) for bi in bounding_boxes[0]]\n",
    "                    x1,y1,x2,y2=b[0:4]\n",
    "                    face_img=image[y1:y2,x1:x2,:]\n",
    "                    \n",
    "                    if np.prod(face_img.shape)==0:\n",
    "                        # print('Empty face ',b,' found for ',filename)\n",
    "                        continue\n",
    "                        \n",
    "                    faceFound=''\n",
    "\n",
    "                # print('/kaggle/working/daisee_test/' + person + '/' + video_name + '_' + str(i+1) + '_' + faceFound + '.png')\n",
    "                cv2.imwrite(save_dir + '/' + person + '/' + video_name + '_' + str(i+1) + '_' + faceFound + '.png', face_img)\n",
    "                # cv2.imwrite(os.path.join(save_path, folder, root+faceFound+ext), face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c41887a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T19:38:02.785757Z",
     "iopub.status.busy": "2023-05-15T19:38:02.785029Z",
     "iopub.status.idle": "2023-05-15T19:38:02.789463Z",
     "shell.execute_reply": "2023-05-15T19:38:02.788658Z"
    },
    "papermill": {
     "duration": 0.014362,
     "end_time": "2023-05-15T19:38:02.791801",
     "exception": false,
     "start_time": "2023-05-15T19:38:02.777439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_video_path = r'/kaggle/input/daisee/DAiSEE/DataSet/Train'\n",
    "val_video_path = r'/kaggle/input/daisee/DAiSEE/DataSet/Validation'\n",
    "test_video_path = r'/kaggle/input/daisee/DAiSEE/DataSet/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cbf93a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T19:38:02.805905Z",
     "iopub.status.busy": "2023-05-15T19:38:02.805180Z",
     "iopub.status.idle": "2023-05-15T21:14:28.097906Z",
     "shell.execute_reply": "2023-05-15T21:14:28.094329Z"
    },
    "papermill": {
     "duration": 5785.30927,
     "end_time": "2023-05-15T21:14:28.107214",
     "exception": false,
     "start_time": "2023-05-15T19:38:02.797944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 17/70 [24:15<1:23:21, 94.36s/it][mpeg4 @ 0x59d9ad6c0100] I cbpy damaged at 16 8\n",
      "[mpeg4 @ 0x59d9ad6c0100] Error at MB: 344\n",
      "100%|██████████| 70/70 [1:36:25<00:00, 82.65s/it]\n"
     ]
    }
   ],
   "source": [
    "extract_and_save_faces(train_video_path, r'/kaggle/working/daisee_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75866d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T21:14:28.138964Z",
     "iopub.status.busy": "2023-05-15T21:14:28.138366Z",
     "iopub.status.idle": "2023-05-15T21:42:31.573972Z",
     "shell.execute_reply": "2023-05-15T21:42:31.572728Z"
    },
    "papermill": {
     "duration": 1683.471068,
     "end_time": "2023-05-15T21:42:31.590843",
     "exception": false,
     "start_time": "2023-05-15T21:14:28.119775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [28:03<00:00, 76.52s/it]\n"
     ]
    }
   ],
   "source": [
    "extract_and_save_faces(val_video_path, r'/kaggle/working/daisee_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5918b69f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T21:42:31.622494Z",
     "iopub.status.busy": "2023-05-15T21:42:31.621748Z",
     "iopub.status.idle": "2023-05-15T21:42:31.626694Z",
     "shell.execute_reply": "2023-05-15T21:42:31.625947Z"
    },
    "papermill": {
     "duration": 0.022992,
     "end_time": "2023-05-15T21:42:31.628635",
     "exception": false,
     "start_time": "2023-05-15T21:42:31.605643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract_and_save_faces(test_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bab1ba",
   "metadata": {
    "papermill": {
     "duration": 0.014585,
     "end_time": "2023-05-15T21:42:31.657682",
     "exception": false,
     "start_time": "2023-05-15T21:42:31.643097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Что нужно для качественного завершения вкр:\n",
    "- лица DAiSEE всех трех выборок\n",
    "- определяем точку, куда в основном смотрят чуваки разных классов на DAiSEE \n",
    "- определяем их поворот по x и y\n",
    "- определяем средний ratio глаза (проверить на наличие азиатов)\n",
    "\n",
    "Так понимаем на train понимаем, какие признаки у каких классов в какую сторону смещены.\n",
    "Затем подбираем пороговые значения, делаем классификацию, замеряем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c35201e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T21:42:31.689819Z",
     "iopub.status.busy": "2023-05-15T21:42:31.688770Z",
     "iopub.status.idle": "2023-05-15T21:42:31.693617Z",
     "shell.execute_reply": "2023-05-15T21:42:31.692739Z"
    },
    "papermill": {
     "duration": 0.023633,
     "end_time": "2023-05-15T21:42:31.695940",
     "exception": false,
     "start_time": "2023-05-15T21:42:31.672307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(r'/kaggle/working')\n",
    "\n",
    "#!tar -czf daisee_test_faces.tar.gz daisee_test\n",
    "\n",
    "#from IPython.display import FileLink\n",
    "\n",
    "# FileLink(r'daisee_test_faces.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5516c7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T21:42:31.727126Z",
     "iopub.status.busy": "2023-05-15T21:42:31.726750Z",
     "iopub.status.idle": "2023-05-15T21:42:31.732191Z",
     "shell.execute_reply": "2023-05-15T21:42:31.731109Z"
    },
    "papermill": {
     "duration": 0.023843,
     "end_time": "2023-05-15T21:42:31.734361",
     "exception": false,
     "start_time": "2023-05-15T21:42:31.710518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree('/kaggle/working/daisee_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7515.601902,
   "end_time": "2023-05-15T21:42:34.750435",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-15T19:37:19.148533",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
